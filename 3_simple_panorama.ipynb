{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "images = [cv2.imread('data/hyu_{}.jpeg'.format(i)) for i in range(3)]\n",
    "grays = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kps = []\n",
    "descs = []\n",
    "for gray in grays:\n",
    "    kp, desc = sift.detectAndCompute(gray, None)\n",
    "    kps.append(kp)\n",
    "    descs.append(desc)\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "matches1 = bf.match(descs[0], descs[1])     # between image 0 and image 1\n",
    "matches2 = bf.match(descs[2], descs[1])     # between image 2 and image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_matches = sorted(matches1, key = lambda x : x.distance)\n",
    "res = cv2.drawMatches(images[0], kps[0], images[1], kps[1], sorted_matches[:50], None, flags = 2)\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_matches = sorted(matches2, key = lambda x : x.distance)\n",
    "res = cv2.drawMatches(images[2], kps[2], images[1], kps[1], sorted_matches[:50], None, flags = 2)\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = images[0].shape\n",
    "result = np.zeros((height, width * 3, 3), dtype = np.uint8)\n",
    "\n",
    "# Stitch image2 to image1\n",
    "src = np.float32([kps[2][m.queryIdx].pt for m in matches2]).reshape((-1, 1, 2))\n",
    "dst = np.float32([kps[1][m.trainIdx].pt for m in matches2]).reshape((-1, 1, 2))\n",
    "H, status = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
    "\n",
    "# Prepare pixel coordinates in image1\n",
    "before = []\n",
    "for x in range(images[1].shape[1]):\n",
    "    for y in range(images[1].shape[0]):\n",
    "        point = [x, y, 1]\n",
    "        before.append(point)\n",
    "before = np.array(before).transpose()\n",
    "\n",
    "# [TODO] Calculate coordinates for each pixel in image1 to image 2\n",
    "after = np.dot(H, before)\n",
    "after = after / after[2, :]\n",
    "after = after[:2, :]\n",
    "after = np.round(after, 0).astype(int)\n",
    "\n",
    "\n",
    "for pt1, pt2 in zip(before[:2, :].transpose(), after.transpose()):\n",
    "    if pt2[1] >= height:\n",
    "        continue\n",
    "\n",
    "    if np.sum(pt2 < 0) >= 1:\n",
    "        continue\n",
    "\n",
    "    result[pt2[1], width+pt2[0]] = images[2][pt1[1], pt1[0]]\n",
    "\n",
    "\n",
    "# Stitch image0 to image1\n",
    "src = np.float32([kps[0][m.queryIdx].pt for m in matches1]).reshape((-1, 1, 2))\n",
    "dst = np.float32([kps[1][m.trainIdx].pt for m in matches1]).reshape((-1, 1, 2))\n",
    "H, status = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
    "\n",
    "\n",
    "# Prepare pixel coordinates in image1\n",
    "before = []\n",
    "for x in range(images[1].shape[1]):\n",
    "    for y in range(images[1].shape[0]):\n",
    "        point = [x, y, 1]\n",
    "        before.append(point)\n",
    "before = np.array(before).transpose()\n",
    "\n",
    "# [TODO] Calculate coordinates for each pixel in image1 to image 0\n",
    "after = np.dot(H, before)\n",
    "after = after / after[2, :]\n",
    "after = after[:2, :]\n",
    "after = after.astype(int)\n",
    "after[0] += width\n",
    "\n",
    "for pt1, pt2 in zip(before[:2, :].transpose(), after.transpose()):\n",
    "    if pt2[1] < 0 or pt2[1] >= height:\n",
    "        continue\n",
    "\n",
    "    if any(pt2 < 0):\n",
    "        continue\n",
    "\n",
    "    result[pt2[1], pt2[0]] = images[0][pt1[1], pt1[0]]\n",
    "result[0:height, width:width*2] = images[1]\n",
    "\n",
    "# Homography calculation\n",
    "def calculate_homography(matches, kp_src, kp_dst):\n",
    "    src_pts = np.float32([kp_src[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp_dst[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return H\n",
    "\n",
    "H0 = calculate_homography(matches1, kps[0], kps[1])\n",
    "H2 = calculate_homography(matches2, kps[2], kps[1])\n",
    "\n",
    "# Determine output size\n",
    "def get_output_size(images, H0, H2):\n",
    "    h1, w1 = images[1].shape[:2]\n",
    "    corners = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Warp corners for all images\n",
    "    corners_0 = cv2.perspectiveTransform(corners, H0)\n",
    "    corners_2 = cv2.perspectiveTransform(corners, H2)\n",
    "    all_corners = np.concatenate((corners, corners_0, corners_2), axis=0)\n",
    "\n",
    "    # Find bounding box\n",
    "    x_min, y_min = np.int32(all_corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(all_corners.max(axis=0).ravel())\n",
    "\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "x_min, y_min, x_max, y_max = get_output_size(images, H0, H2)\n",
    "output_size = (x_max - x_min, y_max - y_min)\n",
    "\n",
    "# Warp images\n",
    "offset = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "H0_offset = offset @ H0\n",
    "H2_offset = offset @ H2\n",
    "\n",
    "result = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "cv2.warpPerspective(images[0], H0_offset, output_size, dst=result, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "cv2.warpPerspective(images[2], H2_offset, output_size, dst=result, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "# Insert the middle image (image 1)\n",
    "x_offset = -x_min\n",
    "y_offset = -y_min\n",
    "result[y_offset:y_offset + images[1].shape[0], x_offset:x_offset + images[1].shape[1]] = images[1]\n",
    "\n",
    "# Feather blending\n",
    "def feather_blend(img1, img2):\n",
    "    mask1 = (img1 > 0).astype(np.float32)\n",
    "    mask2 = (img2 > 0).astype(np.float32)\n",
    "    blended = (img1 * mask1 + img2 * mask2) / (mask1 + mask2 + 1e-5)\n",
    "    return np.clip(blended, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Final blending\n",
    "final_result = feather_blend(result, result)\n",
    "\n",
    "# Show result\n",
    "Image.fromarray(cv2.cvtColor(final_result, cv2.COLOR_BGR2RGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aue8089pa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
